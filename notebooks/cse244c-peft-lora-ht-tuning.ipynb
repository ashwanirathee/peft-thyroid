{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2733529,"sourceType":"datasetVersion","datasetId":1634980},{"sourceId":8669991,"sourceType":"datasetVersion","datasetId":5195844},{"sourceId":12054481,"sourceType":"datasetVersion","datasetId":7577241}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install the requirments for ENV setup","metadata":{}},{"cell_type":"code","source":"!pip install -Uqqq pip --progress-bar off\n!pip install -qqq torch==2.1 --progress-bar off\n!pip install -qqq transformers==4.34.1 --progress-bar off\n!pip install -qqq accelerate==0.23.0 --progress-bar off\n!pip install -qqq bitsandbytes==0.41.1 --progress-bar off\n!pip install -qqq llava-torch==1.1.1 --progress-bar off\n!pip install peft\n# !pip install gdown","metadata":{"execution":{"iopub.status.busy":"2025-06-05T00:29:43.792256Z","iopub.execute_input":"2025-06-05T00:29:43.792722Z","iopub.status.idle":"2025-06-05T00:35:36.504913Z","shell.execute_reply.started":"2025-06-05T00:29:43.792674Z","shell.execute_reply":"2025-06-05T00:35:36.503758Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 2.19.2 requires huggingface-hub>=0.21.2, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab 4.2.1 requires httpx>=0.25.0, but you have httpx 0.24.0 which is incompatible.\njupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkaggle-environments 1.14.11 requires transformers>=4.33.1, but you have transformers 4.31.0 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.10.22 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.4.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.1)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.31.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft) (0.21.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.99)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.99)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.101)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.10.3.66)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.2.10.91)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.0.1)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.4.91)\nRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.14.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.91)\nRequirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.0.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (69.0.3)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (0.42.0)\nRequirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->peft) (4.0.2)\nRequirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->peft) (18.1.8)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.17.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2.32.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (4.66.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft) (2024.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2024.2.2)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# load the lib and modules required for test run of LLMs","metadata":{"execution":{"iopub.status.busy":"2023-11-11T08:40:05.813101Z","iopub.execute_input":"2023-11-11T08:40:05.813542Z","iopub.status.idle":"2023-11-11T08:40:05.818897Z","shell.execute_reply.started":"2023-11-11T08:40:05.813506Z","shell.execute_reply":"2023-11-11T08:40:05.817802Z"}}},{"cell_type":"code","source":"import textwrap\nfrom io import BytesIO\n\nimport requests\nimport torch\nfrom llava.constants import DEFAULT_IMAGE_TOKEN, IMAGE_TOKEN_INDEX\nfrom llava.conversation import SeparatorStyle, conv_templates\nfrom llava.mm_utils import (\n    KeywordsStoppingCriteria,\n    get_model_name_from_path,\n    process_images,\n    tokenizer_image_token,\n)\nfrom llava.model.builder import load_pretrained_model\nfrom llava.utils import disable_torch_init\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nimport numpy as np\nimport gc\nimport pandas as pd\nimport torch.nn.functional as F\nfrom sklearn.metrics import (\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    balanced_accuracy_score,\n    matthews_corrcoef,\n    confusion_matrix,\n    classification_report,\n    roc_auc_score,\n    average_precision_score\n)\nfrom sklearn.preprocessing import label_binarize","metadata":{"execution":{"iopub.status.busy":"2025-06-05T00:35:36.507351Z","iopub.execute_input":"2025-06-05T00:35:36.507691Z","iopub.status.idle":"2025-06-05T00:35:53.937411Z","shell.execute_reply.started":"2025-06-05T00:35:36.507663Z","shell.execute_reply":"2025-06-05T00:35:53.936228Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[2025-06-05 00:35:41,883] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","output_type":"stream"},{"name":"stderr","text":"2025-06-05 00:35:45.099329: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-06-05 00:35:45.099449: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-06-05 00:35:45.235796: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"disable_torch_init()\nMODEL = \"microsoft/llava-med-v1.5-mistral-7b\"\nmodel_name = get_model_name_from_path(MODEL)\nmodel_name","metadata":{"execution":{"iopub.status.busy":"2025-06-05T00:35:53.938828Z","iopub.execute_input":"2025-06-05T00:35:53.939249Z","iopub.status.idle":"2025-06-05T00:35:53.947849Z","shell.execute_reply.started":"2025-06-05T00:35:53.939212Z","shell.execute_reply":"2025-06-05T00:35:53.946583Z"},"trusted":true},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'llava-med-v1.5-mistral-7b'"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Load the test images for testing the model","metadata":{"execution":{"iopub.status.busy":"2023-11-11T08:40:24.801991Z","iopub.execute_input":"2023-11-11T08:40:24.802597Z","iopub.status.idle":"2023-11-11T08:40:24.806589Z","shell.execute_reply.started":"2023-11-11T08:40:24.802563Z","shell.execute_reply":"2023-11-11T08:40:24.805566Z"}}},{"cell_type":"code","source":"tokenizer, model, image_processor, context_len = load_pretrained_model(\n                                                    model_path=MODEL, \n                                                    model_base=None, \n                                                    model_name=model_name, \n                                                    load_8bit=True )","metadata":{"execution":{"iopub.status.busy":"2025-06-05T00:35:53.949731Z","iopub.execute_input":"2025-06-05T00:35:53.950163Z","iopub.status.idle":"2025-06-05T00:38:39.675642Z","shell.execute_reply.started":"2025-06-05T00:35:53.950129Z","shell.execute_reply":"2025-06-05T00:38:39.674687Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a752747dc48c47018bc634240ec99353"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5b661f91a7a4b03b82652d0f526ae41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7c1223f76ca46d8b9d16ec77f2a9797"}},"metadata":{}},{"name":"stderr","text":"You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e80f43cd403438aafd7eabce80806be"}},"metadata":{}},{"name":"stderr","text":"You are using a model of type llava_mistral to instantiate a model of type llava. This is not supported for all configurations of models and can yield errors.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)fetensors.index.json:   0%|          | 0.00/73.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c350194695024d9b91ad93c25e486e61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fe466f8c8f146a5a78270b0846f42fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)of-00004.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa9383e9d34047638e395ec7b9867b8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"771616d1a27a45dcabcba384ca3049b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7de8950b90c24571b1b4523b75baa3ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)of-00004.safetensors:   0%|          | 0.00/262M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22e9a4613bd34bd38ae00ef9154ee4be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/4.76k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a3375fb98154fcf995bd98daef23bca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d2623606ebc4549a7494a12eb021db3"}},"metadata":{}},{"name":"stderr","text":"Some weights of LlavaLlamaForCausalLM were not initialized from the model checkpoint at microsoft/llava-med-v1.5-mistral-7b and are newly initialized: ['model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.31.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.29.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.30.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.28.self_attn.rotary_emb.inv_freq']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d3331c7e97b47678b2bbe53440aafc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)rocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be12a44561b4a769f22aebba76068fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51239a8ea8dc4ee8a3a49a1608746bc3"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Load the saved dataset\ndata = torch.load('/kaggle/input/peft-thyroid-dataset/augmented_dataset.pt', weights_only=False)\n\n# Print sizes\nprint(\"Train images:\", data['train_images'].shape)\nprint(\"Train labels:\", len(data['train_labels']))\nprint(\"Train IDs:\", len(data['train_ids']))  # list of strings\n\nprint(\"Val images:\", data['val_images'].shape)\nprint(\"Val labels:\", len(data['val_labels']))\nprint(\"Val IDs:\", len(data['val_ids']))\n\nprint(\"Test images:\", data['test_images'].shape)\nprint(\"Test labels:\", len(data['test_labels']))\nprint(\"Test IDs:\", len(data['test_ids']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T00:41:38.833411Z","iopub.execute_input":"2025-06-05T00:41:38.834009Z","iopub.status.idle":"2025-06-05T00:41:52.016389Z","shell.execute_reply.started":"2025-06-05T00:41:38.833979Z","shell.execute_reply":"2025-06-05T00:41:52.015324Z"}},"outputs":[{"name":"stdout","text":"Train images: torch.Size([1035, 3, 360, 560])\nTrain labels: 1035\nTrain IDs: 1035\nVal images: (45, 3, 360, 560)\nVal labels: 45\nVal IDs: 45\nTest images: (45, 3, 360, 560)\nTest labels: 45\nTest IDs: 45\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"for name, _ in model.named_modules():\n    if any(x in name for x in target_modules):\n        print(name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T00:41:52.017962Z","iopub.execute_input":"2025-06-05T00:41:52.018243Z","iopub.status.idle":"2025-06-05T00:41:52.837450Z","shell.execute_reply.started":"2025-06-05T00:41:52.018219Z","shell.execute_reply":"2025-06-05T00:41:52.836126Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_modules():\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(x \u001b[38;5;129;01min\u001b[39;00m name \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtarget_modules\u001b[49m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(name)\n","\u001b[0;31mNameError\u001b[0m: name 'target_modules' is not defined"],"ename":"NameError","evalue":"name 'target_modules' is not defined","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"# gc.collect()\n# torch.cuda.empty_cache()\n# model.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)\ntarget_modules = [\n    \"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\",  # from self-attn in vision encoder\n    \"fc1\", \"fc2\",                              # from MLP in vision encoder\n    \"mm_projector.0\", \"mm_projector.2\"         # optional: projector layers if used\n]\n\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    target_modules=target_modules,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"SEQ_CLS\"  # classification\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T00:41:56.714846Z","iopub.execute_input":"2025-06-05T00:41:56.715447Z","iopub.status.idle":"2025-06-05T00:41:57.030862Z","shell.execute_reply.started":"2025-06-05T00:41:56.715417Z","shell.execute_reply":"2025-06-05T00:41:57.029836Z"}},"outputs":[{"name":"stdout","text":"trainable params: 8,364,032 || all params: 7,574,583,296 || trainable%: 0.1104223384066143\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\ndef map_label_to_tirads(label):\n    if \"2\" in label: return \"TI-RADS 2\"\n    elif \"3\" in label: return \"TI-RADS 3\"\n    elif \"4\" in label: return \"TI-RADS 4\"\n    elif \"5\" in label: return \"TI-RADS 5\"\n    else: return \"Unknown\"\n\nclass ThyroidDataset(Dataset):\n    def __init__(self, images, labels):\n        self.images = images\n\n        label_map = {\"TI-RADS 2\": 0, \"TI-RADS 3\": 1, \"TI-RADS 4\": 2, \"TI-RADS 5\": 3}\n        self.labels = []\n\n        for label in labels:\n            if not isinstance(label, str):\n                raise ValueError(f\"Unexpected non-string label: {label}\")\n            coarse_label = map_label_to_tirads(label)\n            if coarse_label not in label_map:\n                raise ValueError(f\"ðŸš¨ Unknown label: {label} â†’ {coarse_label}\")\n            self.labels.append(label_map[coarse_label])\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            'pixel_values': self.images[idx],  # tensor\n            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n        }\n\n\n# Create Datasets\ntrain_dataset = ThyroidDataset(data['train_images'], data['train_labels'])\nval_dataset = ThyroidDataset(data['val_images'], data['val_labels'])\n\n# Dataloaders\ntrain_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T00:43:02.466781Z","iopub.execute_input":"2025-06-05T00:43:02.467806Z","iopub.status.idle":"2025-06-05T00:43:02.477938Z","shell.execute_reply.started":"2025-06-05T00:43:02.467751Z","shell.execute_reply":"2025-06-05T00:43:02.477012Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"device=\"cuda\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T00:42:16.098695Z","iopub.execute_input":"2025-06-05T00:42:16.099075Z","iopub.status.idle":"2025-06-05T00:42:16.103538Z","shell.execute_reply.started":"2025-06-05T00:42:16.099049Z","shell.execute_reply":"2025-06-05T00:42:16.102356Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"if not hasattr(model, \"classifier\"):\n    from torch import nn\n    model.classifier = nn.Linear(model.config.hidden_size, 4).to(device)\n    nn.init.xavier_uniform_(model.classifier.weight)\n    nn.init.zeros_(model.classifier.bias)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T00:42:16.508232Z","iopub.execute_input":"2025-06-05T00:42:16.509287Z","iopub.status.idle":"2025-06-05T00:42:16.522317Z","shell.execute_reply.started":"2025-06-05T00:42:16.509245Z","shell.execute_reply":"2025-06-05T00:42:16.521269Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import gc\nimport torch\n\ngc.collect()\ntorch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T00:43:20.712496Z","iopub.execute_input":"2025-06-05T00:43:20.712901Z","iopub.status.idle":"2025-06-05T00:43:21.083969Z","shell.execute_reply.started":"2025-06-05T00:43:20.712873Z","shell.execute_reply":"2025-06-05T00:43:21.082807Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from tqdm import tqdm\nfrom torch.nn.functional import cross_entropy\n\nclass_labels = [\"TI-RADS 2\", \"TI-RADS 3\", \"TI-RADS 4\", \"TI-RADS 5\"]\nlabel_to_index = {label: i for i, label in enumerate(class_labels)}\n\nmodel.to(device)\nmodel.train()\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n\nfor epoch in range(20):\n    total_loss = 0\n    for batch in tqdm(val_loader):\n        optimizer.zero_grad()\n\n        # Process image\n        processed = image_processor(images=batch['pixel_values'], return_tensors=\"pt\").to(device)\n        pixel_values = processed[\"pixel_values\"]\n\n        batch_size = processed[\"pixel_values\"].size(0)\n        prompts = [\"The TI-RADS classification of the thyroid ultrasound image is:\"] * batch_size\n        inputs = tokenizer(prompts, return_tensors=\"pt\", padding='longest', truncation=True).to(device)\n        \n\n        # Forward pass\n        outputs = model(\n            input_ids=inputs[\"input_ids\"],\n            attention_mask=inputs[\"attention_mask\"],\n            images=pixel_values,\n            output_hidden_states=True,\n            return_dict=True\n        )\n        # print(batch['labels'])\n        true_labels = batch['labels'].to(device)  # Ensure labels are 0â€“3\n        # print(\"Labels:\", true_labels)\n        # print(\"Min label:\", true_labels.min().item(), \"Max label:\", true_labels.max().item())\n        assert torch.all((true_labels >= 0) & (true_labels < 4)), \"ðŸš¨ Invalid label detected!\"\n\n        hidden = outputs.hidden_states[-1][:, -1, :]\n        logits = model.classifier(hidden)  # shape: [B, 4]\n        loss = cross_entropy(logits, true_labels)\n        # print(\"Logits stats â€” mean:\", logits.mean().item(), \"max:\", logits.max().item())\n        # print(\"Loss:\", loss.item())\n        if not torch.isfinite(loss):\n            print(f\"ðŸš¨ Non-finite loss at step {step}, skipping.\")\n            continue\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T00:43:23.769711Z","iopub.execute_input":"2025-06-05T00:43:23.770423Z","iopub.status.idle":"2025-06-05T01:03:03.329082Z","shell.execute_reply.started":"2025-06-05T00:43:23.770393Z","shell.execute_reply":"2025-06-05T01:03:03.328030Z"}},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:04<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Loss = 292.8392\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:04<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Loss = 210.6822\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:03<00:00,  1.40s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Loss = 190.5580\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:01<00:00,  1.37s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Loss = 254.7658\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:58<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Loss = 218.0857\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:57<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Loss = 155.9860\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:58<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Loss = 134.9455\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:57<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Loss = 124.6697\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:57<00:00,  1.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Loss = 120.7542\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:58<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Loss = 118.7797\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:57<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Loss = 115.2528\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:57<00:00,  1.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Loss = 113.4556\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:57<00:00,  1.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Loss = 112.2307\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:57<00:00,  1.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Loss = 109.9046\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:57<00:00,  1.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Loss = 109.8292\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:57<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Loss = 110.1926\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:57<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Loss = 109.1969\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:57<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Loss = 107.8121\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:58<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Loss = 107.0827\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:57<00:00,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Loss = 105.6571\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Save only the LoRA adapter\nmodel.save_pretrained(\"llava-med-lora-train3\")\ntokenizer.save_pretrained(\"llava-med-lora-train3\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_image(image):\n    args = {\"image_aspect_ratio\": \"pad\"}\n    image_tensor = process_images([image], image_processor, args)\n    return image_tensor.to(model.device, dtype=torch.float16)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_prompt(prompt: str):\n    CONV_MODE = 'llava_v0'\n    conv = conv_templates[CONV_MODE].copy()\n    roles = conv.roles\n    prompt = DEFAULT_IMAGE_TOKEN + \"\\n\" + prompt\n    conv.append_message(roles[0], prompt)\n    conv.append_message(roles[1], None)\n    return conv.get_prompt(), conv","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    balanced_accuracy_score, matthews_corrcoef, confusion_matrix,\n    classification_report\n)\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_auc_score, average_precision_score\n\ndef get_report(gt_labels, predicted_labels, all_probs, report_name):\n    print(\"Report:\", report_name)\n    true_labels = gt_labels\n    pred_labels = predicted_labels\n    # Optional: sort class labels explicitly\n    classes = sorted(set(true_labels + pred_labels))  # [2, 3, 4]\n    \n    # Binarize true labels\n    y_true_bin = label_binarize(gt_labels, classes=class_labels)\n    y_prob = np.array(all_probs)\n    \n    # Compute metrics\n    roc_auc = roc_auc_score(y_true_bin, y_prob, average='macro')\n    pr_auc = average_precision_score(y_true_bin, y_prob, average='macro')\n    \n    # Compute standard multi-class metrics\n    metrics = {\n        \"Accuracy\": accuracy_score(true_labels, pred_labels),\n        \"Macro Precision\": precision_score(true_labels, pred_labels, average='macro', zero_division=0),\n        \"Macro Recall\": recall_score(true_labels, pred_labels, average='macro', zero_division=0),\n        \"Macro F1 Score\": f1_score(true_labels, pred_labels, average='macro', zero_division=0),\n        \"Weighted F1 Score\": f1_score(true_labels, pred_labels, average='weighted', zero_division=0),\n        \"Balanced Accuracy\": balanced_accuracy_score(true_labels, pred_labels),\n        \"Matthews Correlation Coefficient\": matthews_corrcoef(true_labels, pred_labels),\n        \"AUC-ROC (macro)\": roc_auc,\n        \"AUC-PR (macro\": pr_auc\n    }\n    \n    # Display metrics summary table\n    metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Score'])\n    print(\"=== Multi-class Summary Metrics ===\")\n    print(metrics_df.round(4))\n    \n    # Optional: show full classification report\n    print(\"\\n=== Per-class Report ===\")\n    print(classification_report(true_labels, pred_labels, digits=4))\n    print(\"\\n========================\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef classify_image_by_logits(image: Image, class_labels: list[str], prompt: str):\n    image_tensor = process_image(image)\n    prompt, conv = create_prompt(prompt)\n    \n    input_ids = tokenizer_image_token(\n        prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\"\n    ).unsqueeze(0).to(model.device)\n\n    with torch.inference_mode():\n        outputs = model(\n            input_ids=input_ids,\n            images=image_tensor,\n            return_dict=True\n        )\n\n    # Get the logits for the next token prediction (only last token in prompt)\n    next_token_logits = outputs.logits[0, -1]  # shape: [vocab_size]\n\n    # Compute logits for all class labels\n    label_scores = []\n    for label in class_labels:\n        token_ids = tokenizer(label, add_special_tokens=False)[\"input_ids\"]\n        logit_sum = sum([next_token_logits[token_id].item() for token_id in token_ids])\n        label_scores.append(logit_sum)\n\n    # Convert logits to probabilities\n    label_scores_tensor = torch.tensor(label_scores)\n    softmax_probs = F.softmax(label_scores_tensor, dim=0).tolist()\n\n    # Get predicted label\n    best_index = int(torch.argmax(label_scores_tensor))\n    predicted_label = class_labels[best_index]\n\n    return predicted_label, softmax_probs\n\ndef map_label_to_tirads(label):\n    if \"2\" in label: return \"TI-RADS 2\"\n    elif \"3\" in label: return \"TI-RADS 3\"\n    elif \"4\" in label: return \"TI-RADS 4\"\n    elif \"5\" in label: return \"TI-RADS 5\"\n    else: return \"Unknown\"\n    \ncustom_prompt = \"The TI-RADS classification of the thyroid ultrasound image is: \"\nclass_labels = [\"TI-RADS 2\", \"TI-RADS 3\", \"TI-RADS 4\", \"TI-RADS 5\"]\n\nprint(len(data['test_labels']))\ngt_labels = []\npredicted_labels = []\nall_probs = []\nfor i in range(len(data['test_labels'])):\n    img_tensor = data['test_images'][i]  # shape: (3, 360, 560)\n\n    gt_label = map_label_to_tirads(data['test_labels'][i])\n    gt_labels.append(gt_label)\n\n    pred, probs = classify_image_by_logits(img_tensor, class_labels, custom_prompt)\n    predicted_labels.append(pred)\n\n    all_probs.append(probs)\n    print(f\"PatientId: {data['test_ids'][i]}, Label:{gt_label}, Predicted: {pred}\")\n\nbaseline_report = get_report(gt_labels, predicted_labels, all_probs, \"Lora Test Data Report\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"custom_prompt = \"The TI-RADS classification of the thyroid ultrasound image is: \"\nclass_labels = [\"TI-RADS 2\", \"TI-RADS 3\", \"TI-RADS 4\", \"TI-RADS 5\"]\n\nprint(len(data['val_labels']))\ngt_labels = []\npredicted_labels = []\nall_probs = []\nfor i in range(len(data['val_labels'])):\n    img_tensor = data['val_images'][i]  # shape: (3, 360, 560)\n\n    gt_label = map_label_to_tirads(data['val_labels'][i])\n    gt_labels.append(gt_label)\n\n    pred, probs = classify_image_by_logits(img_tensor, class_labels, custom_prompt)\n    predicted_labels.append(pred)\n\n    all_probs.append(probs)\n    print(f\"PatientId: {data['val_ids'][i]}, Label:{gt_label}, Predicted: {pred}\")\nbaseline_report = get_report(gt_labels, predicted_labels, all_probs, \"LoRA Val Data Report\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}