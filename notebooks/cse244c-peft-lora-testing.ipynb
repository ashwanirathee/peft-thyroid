{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the requirments for ENV setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T04:29:21.357130Z",
     "iopub.status.busy": "2025-06-05T04:29:21.356873Z",
     "iopub.status.idle": "2025-06-05T04:34:18.143515Z",
     "shell.execute_reply": "2025-06-05T04:34:18.142374Z",
     "shell.execute_reply.started": "2025-06-05T04:29:21.357074Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.19.2 requires huggingface-hub>=0.21.2, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 4.2.1 requires httpx>=0.25.0, but you have httpx 0.24.0 which is incompatible.\n",
      "jupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "kaggle-environments 1.14.11 requires transformers>=4.33.1, but you have transformers 4.31.0 which is incompatible.\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\n",
      "ydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.10.22 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.31.0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft) (0.21.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (69.0.3)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (0.42.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->peft) (4.0.2)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->peft) (18.1.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.17.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (4.66.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft) (2024.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -Uqqq pip --progress-bar off\n",
    "!pip install -qqq torch==2.1 --progress-bar off\n",
    "!pip install -qqq transformers==4.34.1 --progress-bar off\n",
    "!pip install -qqq accelerate==0.23.0 --progress-bar off\n",
    "!pip install -qqq bitsandbytes==0.41.1 --progress-bar off\n",
    "!pip install -qqq llava-torch==1.1.1 --progress-bar off\n",
    "!pip install peft\n",
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T08:40:05.813542Z",
     "iopub.status.busy": "2023-11-11T08:40:05.813101Z",
     "iopub.status.idle": "2023-11-11T08:40:05.818897Z",
     "shell.execute_reply": "2023-11-11T08:40:05.817802Z",
     "shell.execute_reply.started": "2023-11-11T08:40:05.813506Z"
    }
   },
   "source": [
    "# load the lib and modules required for test run of LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T04:34:18.146245Z",
     "iopub.status.busy": "2025-06-05T04:34:18.145919Z",
     "iopub.status.idle": "2025-06-05T04:34:34.382254Z",
     "shell.execute_reply": "2025-06-05T04:34:34.381571Z",
     "shell.execute_reply.started": "2025-06-05T04:34:18.146216Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-05 04:34:22,891] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 04:34:26.352538: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-05 04:34:26.352700: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-05 04:34:26.492756: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "from llava.constants import DEFAULT_IMAGE_TOKEN, IMAGE_TOKEN_INDEX\n",
    "from llava.conversation import SeparatorStyle, conv_templates\n",
    "from llava.mm_utils import (\n",
    "    KeywordsStoppingCriteria,\n",
    "    get_model_name_from_path,\n",
    "    process_images,\n",
    "    tokenizer_image_token,\n",
    ")\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.utils import disable_torch_init\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import numpy as np\n",
    "import gc\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T04:34:34.383464Z",
     "iopub.status.busy": "2025-06-05T04:34:34.383208Z",
     "iopub.status.idle": "2025-06-05T04:34:34.389941Z",
     "shell.execute_reply": "2025-06-05T04:34:34.388975Z",
     "shell.execute_reply.started": "2025-06-05T04:34:34.383444Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llava-med-v1.5-mistral-7b'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disable_torch_init()\n",
    "MODEL = \"microsoft/llava-med-v1.5-mistral-7b\"\n",
    "model_name = get_model_name_from_path(MODEL)\n",
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T08:40:24.802597Z",
     "iopub.status.busy": "2023-11-11T08:40:24.801991Z",
     "iopub.status.idle": "2023-11-11T08:40:24.806589Z",
     "shell.execute_reply": "2023-11-11T08:40:24.805566Z",
     "shell.execute_reply.started": "2023-11-11T08:40:24.802563Z"
    }
   },
   "source": [
    "# Load the test images for testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T04:34:34.391414Z",
     "iopub.status.busy": "2025-06-05T04:34:34.391068Z",
     "iopub.status.idle": "2025-06-05T04:36:44.968882Z",
     "shell.execute_reply": "2025-06-05T04:36:44.968098Z",
     "shell.execute_reply.started": "2025-06-05T04:34:34.391387Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ae89ff62b44a69a68f03c9b8466e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e8af47bc2b4daaa750ec9052d2fcc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f96241aca4e44c49b94143362c7638c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)cial_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d02719620040ed85c8a652c13db794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava_mistral to instantiate a model of type llava. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf6b6c4ab3144a791e420366afd0e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)fetensors.index.json:   0%|          | 0.00/73.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0129ad647ad41898ed0858dda55cfc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52e0f95109d48d7b883f9749128070b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)of-00004.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c339b281824ddfa3d437b7fccbdf53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6c8a7456724afba28fa230c775053f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710fb21576d042a1b6192568190a494a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)of-00004.safetensors:   0%|          | 0.00/262M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b823cb8af64903a85d44d3c7a388c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/4.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77b522a84524d08ad2e04012b8c00e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlavaLlamaForCausalLM were not initialized from the model checkpoint at microsoft/llava-med-v1.5-mistral-7b and are newly initialized: ['model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.29.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.30.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.28.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.31.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080a40aad55848938430f9be10f1a536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c056e4437d740de80c2dbfc3a60bc6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)rocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ad529631544bcb8f3f6d436c7f00fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "                                                    model_path=MODEL, \n",
    "                                                    model_base=None, \n",
    "                                                    model_name=model_name, \n",
    "                                                    load_8bit=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T04:36:44.970710Z",
     "iopub.status.busy": "2025-06-05T04:36:44.970069Z",
     "iopub.status.idle": "2025-06-05T04:36:56.170954Z",
     "shell.execute_reply": "2025-06-05T04:36:56.170119Z",
     "shell.execute_reply.started": "2025-06-05T04:36:44.970682Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: torch.Size([1035, 3, 360, 560])\n",
      "Train labels: 1035\n",
      "Train IDs: 1035\n",
      "Val images: (45, 3, 360, 560)\n",
      "Val labels: 45\n",
      "Val IDs: 45\n",
      "Test images: (45, 3, 360, 560)\n",
      "Test labels: 45\n",
      "Test IDs: 45\n"
     ]
    }
   ],
   "source": [
    "# Load the saved dataset\n",
    "data = torch.load('/kaggle/input/peft-thyroid-dataset/augmented_dataset.pt', weights_only=False)\n",
    "\n",
    "# Print sizes\n",
    "print(\"Train images:\", data['train_images'].shape)\n",
    "print(\"Train labels:\", len(data['train_labels']))\n",
    "print(\"Train IDs:\", len(data['train_ids']))  # list of strings\n",
    "\n",
    "print(\"Val images:\", data['val_images'].shape)\n",
    "print(\"Val labels:\", len(data['val_labels']))\n",
    "print(\"Val IDs:\", len(data['val_ids']))\n",
    "\n",
    "print(\"Test images:\", data['test_images'].shape)\n",
    "print(\"Test labels:\", len(data['test_labels']))\n",
    "print(\"Test IDs:\", len(data['test_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T04:37:14.133919Z",
     "iopub.status.busy": "2025-06-05T04:37:14.133267Z",
     "iopub.status.idle": "2025-06-05T04:37:14.814220Z",
     "shell.execute_reply": "2025-06-05T04:37:14.813232Z",
     "shell.execute_reply.started": "2025-06-05T04:37:14.133889Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_modules' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_modules():\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(x \u001b[38;5;129;01min\u001b[39;00m name \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtarget_modules\u001b[49m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target_modules' is not defined"
     ]
    }
   ],
   "source": [
    "for name, _ in model.named_modules():\n",
    "    if any(x in name for x in target_modules):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T04:37:15.006842Z",
     "iopub.status.busy": "2025-06-05T04:37:15.006201Z",
     "iopub.status.idle": "2025-06-05T04:37:15.715601Z",
     "shell.execute_reply": "2025-06-05T04:37:15.714836Z",
     "shell.execute_reply.started": "2025-06-05T04:37:15.006812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# Path to folder containing adapter_model.bin, adapter_config.json, etc.\n",
    "adapter_path = \"/kaggle/input/llava-med-lora-epoch5/other/default/1/llava-med-lora-train3\"\n",
    "\n",
    "# Attach LoRA to your already-loaded base model\n",
    "model = PeftModel.from_pretrained(model, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T01:29:06.307578Z",
     "iopub.status.busy": "2025-06-05T01:29:06.306873Z",
     "iopub.status.idle": "2025-06-05T01:29:06.63874Z",
     "shell.execute_reply": "2025-06-05T01:29:06.637668Z",
     "shell.execute_reply.started": "2025-06-05T01:29:06.307543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "target_modules = [\n",
    "    \"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\",  # from self-attn in vision encoder\n",
    "    \"fc1\", \"fc2\",                              # from MLP in vision encoder\n",
    "    \"mm_projector.0\", \"mm_projector.2\"         # optional: projector layers if used\n",
    "]\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=target_modules,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"  # classification\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T01:29:31.391063Z",
     "iopub.status.busy": "2025-06-05T01:29:31.390027Z",
     "iopub.status.idle": "2025-06-05T01:29:31.403843Z",
     "shell.execute_reply": "2025-06-05T01:29:31.40291Z",
     "shell.execute_reply.started": "2025-06-05T01:29:31.39101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def map_label_to_tirads(label):\n",
    "    if \"2\" in label: return \"TI-RADS 2\"\n",
    "    elif \"3\" in label: return \"TI-RADS 3\"\n",
    "    elif \"4\" in label: return \"TI-RADS 4\"\n",
    "    elif \"5\" in label: return \"TI-RADS 5\"\n",
    "    else: return \"Unknown\"\n",
    "\n",
    "class ThyroidDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "\n",
    "        label_map = {\"TI-RADS 2\": 0, \"TI-RADS 3\": 1, \"TI-RADS 4\": 2, \"TI-RADS 5\": 3}\n",
    "        self.labels = []\n",
    "\n",
    "        for label in labels:\n",
    "            if not isinstance(label, str):\n",
    "                raise ValueError(f\"Unexpected non-string label: {label}\")\n",
    "            coarse_label = map_label_to_tirads(label)\n",
    "            if coarse_label not in label_map:\n",
    "                raise ValueError(f\"üö® Unknown label: {label} ‚Üí {coarse_label}\")\n",
    "            self.labels.append(label_map[coarse_label])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'pixel_values': self.images[idx],  # tensor\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = ThyroidDataset(data['train_images'], data['train_labels'])\n",
    "val_dataset = ThyroidDataset(data['val_images'], data['val_labels'])\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T01:29:31.405591Z",
     "iopub.status.busy": "2025-06-05T01:29:31.405334Z",
     "iopub.status.idle": "2025-06-05T01:29:31.425896Z",
     "shell.execute_reply": "2025-06-05T01:29:31.425009Z",
     "shell.execute_reply.started": "2025-06-05T01:29:31.40557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T01:29:32.428338Z",
     "iopub.status.busy": "2025-06-05T01:29:32.427492Z",
     "iopub.status.idle": "2025-06-05T01:29:32.441756Z",
     "shell.execute_reply": "2025-06-05T01:29:32.441082Z",
     "shell.execute_reply.started": "2025-06-05T01:29:32.428308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if not hasattr(model, \"classifier\"):\n",
    "    from torch import nn\n",
    "    model.classifier = nn.Linear(model.config.hidden_size, 4).to(device)\n",
    "    nn.init.xavier_uniform_(model.classifier.weight)\n",
    "    nn.init.zeros_(model.classifier.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T03:41:16.872339Z",
     "iopub.status.busy": "2025-06-05T03:41:16.871421Z",
     "iopub.status.idle": "2025-06-05T03:41:17.205443Z",
     "shell.execute_reply": "2025-06-05T03:41:17.204394Z",
     "shell.execute_reply.started": "2025-06-05T03:41:16.872294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T01:29:57.965945Z",
     "iopub.status.busy": "2025-06-05T01:29:57.965534Z",
     "iopub.status.idle": "2025-06-05T01:29:57.970321Z",
     "shell.execute_reply": "2025-06-05T01:29:57.969415Z",
     "shell.execute_reply.started": "2025-06-05T01:29:57.965912Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T01:30:57.373192Z",
     "iopub.status.busy": "2025-06-05T01:30:57.372847Z",
     "iopub.status.idle": "2025-06-05T03:39:19.390685Z",
     "shell.execute_reply": "2025-06-05T03:39:19.389509Z",
     "shell.execute_reply.started": "2025-06-05T01:30:57.373167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.nn.functional import cross_entropy\n",
    "class_labels = [\"TI-RADS 2\", \"TI-RADS 3\", \"TI-RADS 4\", \"TI-RADS 5\"]\n",
    "label_to_index = {label: i for i, label in enumerate(class_labels)}\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-5,\n",
    "    weight_decay=0.0\n",
    ")\n",
    "num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"üîç Trainable parameters: {num_trainable}\")\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        processed = image_processor(images=batch['pixel_values'], return_tensors=\"pt\").to(device)\n",
    "        pixel_values = processed[\"pixel_values\"]\n",
    "        batch_size = pixel_values.size(0)\n",
    "        prompts = [\"The TI-RADS classification of the thyroid ultrasound image is:\"] * batch_size\n",
    "        inputs = tokenizer(prompts, return_tensors=\"pt\", padding='longest', truncation=True).to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            images=pixel_values,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "        true_labels = batch['labels'].to(device)\n",
    "        hidden = outputs.hidden_states[-1][:, -1, :]\n",
    "        logits = model.classifier(hidden)\n",
    "        loss = cross_entropy(logits, true_labels)\n",
    "        if not torch.isfinite(loss):\n",
    "            continue\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {total_loss:.4f}\")\n",
    "\n",
    "    # === Validation loss ===\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            processed = image_processor(images=batch['pixel_values'], return_tensors=\"pt\").to(device)\n",
    "            pixel_values = processed[\"pixel_values\"]\n",
    "            batch_size = pixel_values.size(0)\n",
    "            prompts = [\"The TI-RADS classification of the thyroid ultrasound image is:\"] * batch_size\n",
    "            inputs = tokenizer(prompts, return_tensors=\"pt\", padding='longest', truncation=True).to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                images=pixel_values,\n",
    "                output_hidden_states=True,\n",
    "                return_dict=True\n",
    "            )\n",
    "            true_labels = batch['labels'].to(device)\n",
    "            hidden = outputs.hidden_states[-1][:, -1, :]\n",
    "            logits = model.classifier(hidden)\n",
    "            val_loss += cross_entropy(logits, true_labels).item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Validation Loss = {val_loss:.4f}\")\n",
    "\n",
    "    # === Checkpointing ===\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        torch.save(model.state_dict(), f\"checkpoint_epoch_{epoch+1}.pt\")\n",
    "        print(f\"‚úÖ Model checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "    # === Early stopping ===\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"‚èπÔ∏è Early stopping triggered at epoch {epoch+1}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T03:39:23.572722Z",
     "iopub.status.busy": "2025-06-05T03:39:23.572339Z",
     "iopub.status.idle": "2025-06-05T03:39:23.687699Z",
     "shell.execute_reply": "2025-06-05T03:39:23.68686Z",
     "shell.execute_reply.started": "2025-06-05T03:39:23.572687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save only the LoRA adapter\n",
    "model.save_pretrained(\"llava-med-lora-train3\")\n",
    "tokenizer.save_pretrained(\"llava-med-lora-train3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T04:37:26.701985Z",
     "iopub.status.busy": "2025-06-05T04:37:26.701043Z",
     "iopub.status.idle": "2025-06-05T04:37:26.706666Z",
     "shell.execute_reply": "2025-06-05T04:37:26.705714Z",
     "shell.execute_reply.started": "2025-06-05T04:37:26.701954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    args = {\"image_aspect_ratio\": \"pad\"}\n",
    "    image_tensor = process_images([image], image_processor, args)\n",
    "    return image_tensor.to(model.device, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T04:37:27.216264Z",
     "iopub.status.busy": "2025-06-05T04:37:27.215896Z",
     "iopub.status.idle": "2025-06-05T04:37:27.221168Z",
     "shell.execute_reply": "2025-06-05T04:37:27.220347Z",
     "shell.execute_reply.started": "2025-06-05T04:37:27.216237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_prompt(prompt: str):\n",
    "    CONV_MODE = 'llava_v0'\n",
    "    conv = conv_templates[CONV_MODE].copy()\n",
    "    roles = conv.roles\n",
    "    prompt = DEFAULT_IMAGE_TOKEN + \"\\n\" + prompt\n",
    "    conv.append_message(roles[0], prompt)\n",
    "    conv.append_message(roles[1], None)\n",
    "    return conv.get_prompt(), conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T04:37:29.644139Z",
     "iopub.status.busy": "2025-06-05T04:37:29.643470Z",
     "iopub.status.idle": "2025-06-05T04:37:29.651725Z",
     "shell.execute_reply": "2025-06-05T04:37:29.650919Z",
     "shell.execute_reply.started": "2025-06-05T04:37:29.644112Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    balanced_accuracy_score, matthews_corrcoef, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "def get_report(gt_labels, predicted_labels, all_probs, report_name):\n",
    "    print(\"Report:\", report_name)\n",
    "    true_labels = gt_labels\n",
    "    pred_labels = predicted_labels\n",
    "    # Optional: sort class labels explicitly\n",
    "    classes = sorted(set(true_labels + pred_labels))  # [2, 3, 4]\n",
    "    \n",
    "    # Binarize true labels\n",
    "    y_true_bin = label_binarize(gt_labels, classes=class_labels)\n",
    "    y_prob = np.array(all_probs)\n",
    "    \n",
    "    # Compute metrics\n",
    "    roc_auc = roc_auc_score(y_true_bin, y_prob, average='macro')\n",
    "    pr_auc = average_precision_score(y_true_bin, y_prob, average='macro')\n",
    "    \n",
    "    # Compute standard multi-class metrics\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(true_labels, pred_labels),\n",
    "        \"Macro Precision\": precision_score(true_labels, pred_labels, average='macro', zero_division=0),\n",
    "        \"Macro Recall\": recall_score(true_labels, pred_labels, average='macro', zero_division=0),\n",
    "        \"Macro F1 Score\": f1_score(true_labels, pred_labels, average='macro', zero_division=0),\n",
    "        \"Weighted F1 Score\": f1_score(true_labels, pred_labels, average='weighted', zero_division=0),\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(true_labels, pred_labels),\n",
    "        \"Matthews Correlation Coefficient\": matthews_corrcoef(true_labels, pred_labels),\n",
    "        \"AUC-ROC (macro)\": roc_auc,\n",
    "        \"AUC-PR (macro\": pr_auc\n",
    "    }\n",
    "    \n",
    "    # Display metrics summary table\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Score'])\n",
    "    print(\"=== Multi-class Summary Metrics ===\")\n",
    "    print(metrics_df.round(4))\n",
    "    \n",
    "    # Optional: show full classification report\n",
    "    print(\"\\n=== Per-class Report ===\")\n",
    "    print(classification_report(true_labels, pred_labels, digits=4))\n",
    "    print(\"\\n========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T04:37:53.364915Z",
     "iopub.status.busy": "2025-06-05T04:37:53.364609Z",
     "iopub.status.idle": "2025-06-05T04:39:44.668938Z",
     "shell.execute_reply": "2025-06-05T04:39:44.668065Z",
     "shell.execute_reply.started": "2025-06-05T04:37:53.364894Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "PatientId: 259, Label:TI-RADS 3, Predicted: TI-RADS 2\n",
      "PatientId: 18, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 91, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 79, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 311, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 32, Label:TI-RADS 2, Predicted: TI-RADS 3\n",
      "PatientId: 198, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 176, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 83, Label:TI-RADS 5, Predicted: TI-RADS 5\n",
      "PatientId: 346, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 204, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 20, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 129, Label:TI-RADS 3, Predicted: TI-RADS 2\n",
      "PatientId: 110, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 22, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 105, Label:TI-RADS 3, Predicted: TI-RADS 4\n",
      "PatientId: 53, Label:TI-RADS 4, Predicted: TI-RADS 3\n",
      "PatientId: 12, Label:TI-RADS 4, Predicted: TI-RADS 3\n",
      "PatientId: 269, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 135, Label:TI-RADS 5, Predicted: TI-RADS 4\n",
      "PatientId: 373, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 376, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 242, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 251, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 207, Label:TI-RADS 3, Predicted: TI-RADS 4\n",
      "PatientId: 203, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 248, Label:TI-RADS 2, Predicted: TI-RADS 4\n",
      "PatientId: 399, Label:TI-RADS 2, Predicted: TI-RADS 2\n",
      "PatientId: 369, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 19, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 286, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 313, Label:TI-RADS 5, Predicted: TI-RADS 4\n",
      "PatientId: 202, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 382, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 337, Label:TI-RADS 2, Predicted: TI-RADS 4\n",
      "PatientId: 81, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 359, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 108, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 303, Label:TI-RADS 2, Predicted: TI-RADS 4\n",
      "PatientId: 293, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 383, Label:TI-RADS 5, Predicted: TI-RADS 4\n",
      "PatientId: 295, Label:TI-RADS 4, Predicted: TI-RADS 3\n",
      "PatientId: 197, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 387, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 70, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "Report: Lora Test Data Report\n",
      "=== Multi-class Summary Metrics ===\n",
      "                                   Score\n",
      "Accuracy                          0.6889\n",
      "Macro Precision                   0.5293\n",
      "Macro Recall                      0.3391\n",
      "Macro F1 Score                    0.3726\n",
      "Weighted F1 Score                 0.6611\n",
      "Balanced Accuracy                 0.3391\n",
      "Matthews Correlation Coefficient  0.2282\n",
      "AUC-ROC (macro)                   0.4711\n",
      "AUC-PR (macro                     0.3441\n",
      "\n",
      "=== Per-class Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   TI-RADS 2     0.3333    0.2000    0.2500         5\n",
      "   TI-RADS 3     0.0000    0.0000    0.0000         4\n",
      "   TI-RADS 4     0.7838    0.9062    0.8406        32\n",
      "   TI-RADS 5     1.0000    0.2500    0.4000         4\n",
      "\n",
      "    accuracy                         0.6889        45\n",
      "   macro avg     0.5293    0.3391    0.3726        45\n",
      "weighted avg     0.6833    0.6889    0.6611        45\n",
      "\n",
      "\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def classify_image_by_logits(image: Image, class_labels: list[str], prompt: str):\n",
    "    image_tensor = process_image(image)\n",
    "    prompt, conv = create_prompt(prompt)\n",
    "    \n",
    "    input_ids = tokenizer_image_token(\n",
    "        prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\"\n",
    "    ).unsqueeze(0).to(model.device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            images=image_tensor,\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "    # Get the logits for the next token prediction (only last token in prompt)\n",
    "    next_token_logits = outputs.logits[0, -1]  # shape: [vocab_size]\n",
    "\n",
    "    # Compute logits for all class labels\n",
    "    label_scores = []\n",
    "    for label in class_labels:\n",
    "        token_ids = tokenizer(label, add_special_tokens=False)[\"input_ids\"]\n",
    "        logit_sum = sum([next_token_logits[token_id].item() for token_id in token_ids])\n",
    "        label_scores.append(logit_sum)\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    label_scores_tensor = torch.tensor(label_scores)\n",
    "    softmax_probs = F.softmax(label_scores_tensor, dim=0).tolist()\n",
    "\n",
    "    # Get predicted label\n",
    "    best_index = int(torch.argmax(label_scores_tensor))\n",
    "    predicted_label = class_labels[best_index]\n",
    "\n",
    "    return predicted_label, softmax_probs\n",
    "\n",
    "def map_label_to_tirads(label):\n",
    "    if \"2\" in label: return \"TI-RADS 2\"\n",
    "    elif \"3\" in label: return \"TI-RADS 3\"\n",
    "    elif \"4\" in label: return \"TI-RADS 4\"\n",
    "    elif \"5\" in label: return \"TI-RADS 5\"\n",
    "    else: return \"Unknown\"\n",
    "    \n",
    "custom_prompt = \"The TI-RADS classification of the thyroid ultrasound image is: \"\n",
    "class_labels = [\"TI-RADS 2\", \"TI-RADS 3\", \"TI-RADS 4\", \"TI-RADS 5\"]\n",
    "model.eval()\n",
    "print(len(data['test_labels']))\n",
    "gt_labels = []\n",
    "predicted_labels = []\n",
    "all_probs = []\n",
    "for i in range(len(data['test_labels'])):\n",
    "    img_tensor = data['test_images'][i]  # shape: (3, 360, 560)\n",
    "\n",
    "    gt_label = map_label_to_tirads(data['test_labels'][i])\n",
    "    gt_labels.append(gt_label)\n",
    "\n",
    "    pred, probs = classify_image_by_logits(img_tensor, class_labels, custom_prompt)\n",
    "    predicted_labels.append(pred)\n",
    "\n",
    "    all_probs.append(probs)\n",
    "    print(f\"PatientId: {data['test_ids'][i]}, Label:{gt_label}, Predicted: {pred}\")\n",
    "\n",
    "baseline_report = get_report(gt_labels, predicted_labels, all_probs, \"Lora Test Data Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T04:40:50.077653Z",
     "iopub.status.busy": "2025-06-05T04:40:50.076796Z",
     "iopub.status.idle": "2025-06-05T04:42:35.599239Z",
     "shell.execute_reply": "2025-06-05T04:42:35.598308Z",
     "shell.execute_reply.started": "2025-06-05T04:40:50.077623Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "PatientId: 233, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 76, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 30, Label:TI-RADS 5, Predicted: TI-RADS 4\n",
      "PatientId: 141, Label:TI-RADS 4, Predicted: TI-RADS 3\n",
      "PatientId: 217, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 11, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 378, Label:TI-RADS 4, Predicted: TI-RADS 3\n",
      "PatientId: 334, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 74, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 247, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 89, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 192, Label:TI-RADS 2, Predicted: TI-RADS 4\n",
      "PatientId: 343, Label:TI-RADS 4, Predicted: TI-RADS 3\n",
      "PatientId: 179, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 220, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 227, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 5, Label:TI-RADS 2, Predicted: TI-RADS 2\n",
      "PatientId: 335, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 372, Label:TI-RADS 5, Predicted: TI-RADS 4\n",
      "PatientId: 302, Label:TI-RADS 2, Predicted: TI-RADS 4\n",
      "PatientId: 270, Label:TI-RADS 2, Predicted: TI-RADS 4\n",
      "PatientId: 107, Label:TI-RADS 2, Predicted: TI-RADS 4\n",
      "PatientId: 320, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 122, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 374, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 128, Label:TI-RADS 5, Predicted: TI-RADS 4\n",
      "PatientId: 118, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 331, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 126, Label:TI-RADS 3, Predicted: TI-RADS 2\n",
      "PatientId: 304, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 21, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 78, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 361, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 333, Label:TI-RADS 5, Predicted: TI-RADS 4\n",
      "PatientId: 160, Label:TI-RADS 4, Predicted: TI-RADS 3\n",
      "PatientId: 185, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 162, Label:TI-RADS 2, Predicted: TI-RADS 4\n",
      "PatientId: 284, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 201, Label:TI-RADS 2, Predicted: TI-RADS 3\n",
      "PatientId: 360, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 398, Label:TI-RADS 2, Predicted: TI-RADS 4\n",
      "PatientId: 68, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 27, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 155, Label:TI-RADS 4, Predicted: TI-RADS 4\n",
      "PatientId: 94, Label:TI-RADS 5, Predicted: TI-RADS 4\n",
      "Report: LoRA Val Data Report\n",
      "=== Multi-class Summary Metrics ===\n",
      "                                   Score\n",
      "Accuracy                          0.6222\n",
      "Macro Precision                   0.3026\n",
      "Macro Recall                      0.2490\n",
      "Macro F1 Score                    0.2457\n",
      "Weighted F1 Score                 0.5747\n",
      "Balanced Accuracy                 0.2490\n",
      "Matthews Correlation Coefficient  0.0832\n",
      "AUC-ROC (macro)                   0.4987\n",
      "AUC-PR (macro                     0.3475\n",
      "\n",
      "=== Per-class Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   TI-RADS 2     0.5000    0.1250    0.2000         8\n",
      "   TI-RADS 3     0.0000    0.0000    0.0000         1\n",
      "   TI-RADS 4     0.7105    0.8710    0.7826        31\n",
      "   TI-RADS 5     0.0000    0.0000    0.0000         5\n",
      "\n",
      "    accuracy                         0.6222        45\n",
      "   macro avg     0.3026    0.2490    0.2457        45\n",
      "weighted avg     0.5784    0.6222    0.5747        45\n",
      "\n",
      "\n",
      "========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "custom_prompt = \"The TI-RADS classification of the thyroid ultrasound image is: \"\n",
    "class_labels = [\"TI-RADS 2\", \"TI-RADS 3\", \"TI-RADS 4\", \"TI-RADS 5\"]\n",
    "model.eval()\n",
    "print(len(data['val_labels']))\n",
    "gt_labels = []\n",
    "predicted_labels = []\n",
    "all_probs = []\n",
    "for i in range(len(data['val_labels'])):\n",
    "    img_tensor = data['val_images'][i]  # shape: (3, 360, 560)\n",
    "\n",
    "    gt_label = map_label_to_tirads(data['val_labels'][i])\n",
    "    gt_labels.append(gt_label)\n",
    "\n",
    "    pred, probs = classify_image_by_logits(img_tensor, class_labels, custom_prompt)\n",
    "    predicted_labels.append(pred)\n",
    "\n",
    "    all_probs.append(probs)\n",
    "    print(f\"PatientId: {data['val_ids'][i]}, Label:{gt_label}, Predicted: {pred}\")\n",
    "baseline_report = get_report(gt_labels, predicted_labels, all_probs, \"LoRA Val Data Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1634980,
     "sourceId": 2733529,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7577241,
     "sourceId": 12054481,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
